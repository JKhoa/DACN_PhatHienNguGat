#!/usr/bin/env python3
"""
BÃ¡o cÃ¡o Tá»•ng há»£p Káº¿t quáº£ Training 1000 Epochs
==========================================

Script nÃ y sáº½ phÃ¢n tÃ­ch vÃ  bÃ¡o cÃ¡o táº¥t cáº£ káº¿t quáº£ training tá»« cÃ¡c models
YOLOv5, YOLOv8, vÃ  YOLOv11 sau quÃ¡ trÃ¬nh training 1000 epochs.
"""

import os
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import glob

class TrainingResultsAnalyzer:
    """PhÃ¢n tÃ­ch káº¿t quáº£ training tá»•ng há»£p"""
    
    def __init__(self):
        self.root_dir = Path("..").resolve()
        self.runs_dir = self.root_dir / "runs" / "pose-train"
        self.backup_dir = self.root_dir / "model_backups_1000ep"
        self.results_dir = self.root_dir / "training_results_1000ep"
        
        self.analysis_results = {}
        
    def analyze_training_runs(self):
        """PhÃ¢n tÃ­ch cÃ¡c training runs"""
        print("ğŸ” Analyzing training runs...")
        print(f"ğŸ“‚ Looking in: {self.runs_dir}")
        
        if not self.runs_dir.exists():
            print("âŒ No training runs directory found")
            return {}
            
        runs_analysis = {}
        
        for run_dir in self.runs_dir.iterdir():
            if run_dir.is_dir():
                print(f"\nğŸ“ Checking: {run_dir.name}")
                
                # PhÃ¢n tÃ­ch weights
                weights_dir = run_dir / "weights"
                weights_info = {}
                
                if weights_dir.exists():
                    for weight_file in weights_dir.glob("*.pt"):
                        size_mb = weight_file.stat().st_size / 1024 / 1024
                        weights_info[weight_file.name] = {
                            "size_mb": size_mb,
                            "created": datetime.fromtimestamp(weight_file.stat().st_mtime).isoformat()
                        }
                        print(f"   ğŸ’¾ Found: {weight_file.name} ({size_mb:.1f}MB)")
                
                # PhÃ¢n tÃ­ch results.csv náº¿u cÃ³
                results_csv = run_dir / "results.csv"
                training_metrics = {}
                
                if results_csv.exists():
                    try:
                        df = pd.read_csv(results_csv)
                        if len(df) > 0:
                            # TÃ¬m cÃ¡c cá»™t cÃ³ sáºµn
                            available_cols = df.columns.tolist()
                            print(f"   ğŸ“Š CSV columns: {len(available_cols)} columns")
                            
                            training_metrics = {
                                "epochs_completed": len(df),
                                "csv_columns": available_cols[:10]  # Láº¥y 10 cá»™t Ä‘áº§u tiÃªn
                            }
                            
                            # ThÃªm metrics náº¿u cÃ³
                            metrics_cols = [col for col in df.columns if 'mAP' in col or 'loss' in col]
                            if metrics_cols:
                                last_row = df.iloc[-1]
                                for col in metrics_cols[:5]:  # Láº¥y 5 metrics Ä‘áº§u tiÃªn
                                    training_metrics[f"final_{col}"] = float(last_row[col]) if pd.notna(last_row[col]) else None
                                    
                                # Best values
                                for col in metrics_cols[:5]:
                                    if 'mAP' in col:
                                        training_metrics[f"best_{col}"] = float(df[col].max()) if pd.notna(df[col].max()) else None
                            
                            print(f"   ğŸ“ˆ Epochs completed: {training_metrics['epochs_completed']}")
                            
                    except Exception as e:
                        print(f"   âŒ Error reading results.csv: {e}")
                        training_metrics = {"error": str(e)}
                
                # Kiá»ƒm tra log files
                log_files = list(run_dir.glob("*.log")) + list(run_dir.glob("*.txt"))
                log_info = {}
                for log_file in log_files:
                    size_kb = log_file.stat().st_size / 1024
                    log_info[log_file.name] = {"size_kb": size_kb}
                
                runs_analysis[run_dir.name] = {
                    "weights": weights_info,
                    "metrics": training_metrics,
                    "logs": log_info,
                    "status": "completed" if "best.pt" in weights_info else "incomplete"
                }
        
        self.analysis_results["training_runs"] = runs_analysis
        return runs_analysis
    
    def analyze_model_backups(self):
        """PhÃ¢n tÃ­ch model backups"""
        print(f"\nğŸ” Analyzing model backups...")
        print(f"ğŸ“‚ Looking in: {self.backup_dir}")
        
        if not self.backup_dir.exists():
            print("âŒ No backup directory found")
            return {}
            
        backups_analysis = {}
        
        for backup_file in self.backup_dir.glob("*.pt"):
            size_mb = backup_file.stat().st_size / 1024 / 1024
            created = datetime.fromtimestamp(backup_file.stat().st_mtime)
            
            backups_analysis[backup_file.name] = {
                "size_mb": size_mb,
                "created": created.isoformat(),
                "model_type": self._extract_model_type(backup_file.name)
            }
            print(f"   ğŸ’¾ {backup_file.name}: {size_mb:.1f}MB")
        
        self.analysis_results["model_backups"] = backups_analysis
        return backups_analysis
    
    def analyze_training_reports(self):
        """PhÃ¢n tÃ­ch training reports"""
        print(f"\nğŸ” Analyzing training reports...")
        print(f"ğŸ“‚ Looking in: {self.results_dir}")
        
        if not self.results_dir.exists():
            print("âŒ No results directory found")
            return {}
            
        reports_analysis = {}
        
        # TÃ¬m táº¥t cáº£ JSON files
        for report_file in self.results_dir.glob("*.json"):
            try:
                with open(report_file, 'r', encoding='utf-8') as f:
                    report_data = json.load(f)
                    reports_analysis[report_file.name] = report_data
                    print(f"   ğŸ“„ {report_file.name}: loaded")
            except Exception as e:
                print(f"   âŒ Error reading {report_file.name}: {e}")
        
        # TÃ¬m log files
        for log_file in self.results_dir.glob("*.log"):
            size_kb = log_file.stat().st_size / 1024
            print(f"   ğŸ“ {log_file.name}: {size_kb:.1f}KB")
        
        self.analysis_results["training_reports"] = reports_analysis
        return reports_analysis
    
    def check_existing_models(self):
        """Kiá»ƒm tra models hiá»‡n cÃ³"""
        print(f"\nğŸ” Checking existing models in root directory...")
        
        model_files = {}
        
        # TÃ¬m trong thÆ° má»¥c gá»‘c
        for pattern in ["*.pt", "yolo*.pt"]:
            for model_file in self.root_dir.glob(pattern):
                if model_file.is_file():
                    size_mb = model_file.stat().st_size / 1024 / 1024
                    created = datetime.fromtimestamp(model_file.stat().st_mtime)
                    
                    model_files[model_file.name] = {
                        "size_mb": size_mb,
                        "created": created.isoformat(),
                        "model_type": self._extract_model_type(model_file.name),
                        "path": str(model_file)
                    }
                    print(f"   ğŸ¤– {model_file.name}: {size_mb:.1f}MB")
        
        self.analysis_results["existing_models"] = model_files
        return model_files
    
    def check_training_logs(self):
        """Kiá»ƒm tra training logs"""
        print(f"\nğŸ” Checking training logs...")
        
        log_files = {}
        
        # TÃ¬m trong tools directory
        tools_dir = Path(".")
        for log_file in tools_dir.glob("*.log"):
            size_kb = log_file.stat().st_size / 1024
            modified = datetime.fromtimestamp(log_file.stat().st_mtime)
            
            log_files[log_file.name] = {
                "size_kb": size_kb,
                "modified": modified.isoformat(),
                "path": str(log_file)
            }
            print(f"   ğŸ“ {log_file.name}: {size_kb:.1f}KB (modified: {modified.strftime('%Y-%m-%d %H:%M')})")
        
        self.analysis_results["training_logs"] = log_files
        return log_files
    
    def _extract_model_type(self, filename):
        """TrÃ­ch xuáº¥t loáº¡i model tá»« tÃªn file"""
        filename_lower = filename.lower()
        if "yolov11" in filename_lower or "v11" in filename_lower:
            return "YOLOv11"
        elif "yolov8" in filename_lower or "v8" in filename_lower:
            return "YOLOv8"
        elif "yolov5" in filename_lower or "v5" in filename_lower:
            return "YOLOv5"
        else:
            return "Unknown"
    
    def generate_comprehensive_report(self):
        """Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p"""
        print("\nğŸ“‹ Generating comprehensive report...")
        print("="*80)
        
        # PhÃ¢n tÃ­ch táº¥t cáº£ dá»¯ liá»‡u
        runs_analysis = self.analyze_training_runs()
        backups_analysis = self.analyze_model_backups()
        reports_analysis = self.analyze_training_reports()
        existing_models = self.check_existing_models()
        training_logs = self.check_training_logs()
        
        # Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p
        report = {
            "report_generated": datetime.now().isoformat(),
            "analysis_summary": {
                "total_training_runs": len(runs_analysis),
                "completed_runs": sum(1 for r in runs_analysis.values() if r.get("status") == "completed"),
                "total_model_backups": len(backups_analysis),
                "total_training_reports": len(reports_analysis),
                "existing_models_count": len(existing_models),
                "training_logs_count": len(training_logs)
            },
            "detailed_analysis": self.analysis_results
        }
        
        # LÆ°u bÃ¡o cÃ¡o
        report_filename = f"comprehensive_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path = Path(".") / report_filename
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        # In bÃ¡o cÃ¡o tÃ³m táº¯t
        self.print_summary_report(report)
        
        return report_path
    
    def print_summary_report(self, report):
        """In bÃ¡o cÃ¡o tÃ³m táº¯t"""
        print("\n" + "="*80)
        print("ğŸ‰ BÃO CÃO Tá»”NG Há»¢P TRAINING 1000 EPOCHS")
        print("="*80)
        
        summary = report["analysis_summary"]
        print(f"\nğŸ“Š Tá»”NG QUAN:")
        print(f"   ğŸƒ Tá»•ng sá»‘ training runs: {summary['total_training_runs']}")
        print(f"   âœ… Runs hoÃ n thÃ nh: {summary['completed_runs']}")
        print(f"   ğŸ’¾ Model backups: {summary['total_model_backups']}")
        print(f"   ğŸ“„ Training reports: {summary['total_training_reports']}")
        print(f"   ğŸ¤– Models hiá»‡n cÃ³: {summary['existing_models_count']}")
        print(f"   ğŸ“ Training logs: {summary['training_logs_count']}")
        
        # Chi tiáº¿t training runs
        runs = self.analysis_results.get("training_runs", {})
        if runs:
            print(f"\nğŸƒ CHI TIáº¾T TRAINING RUNS:")
            for run_name, run_data in runs.items():
                model_type = self._extract_model_type(run_name)
                metrics = run_data.get("metrics", {})
                status = run_data.get("status", "unknown")
                weights = run_data.get("weights", {})
                
                print(f"\n   ğŸ“ {model_type} - {run_name}:")
                print(f"      ğŸ“Š Status: {status}")
                
                if "epochs_completed" in metrics:
                    print(f"      ğŸ¯ Epochs completed: {metrics['epochs_completed']}")
                
                if "error" in metrics:
                    print(f"      âŒ Error: {metrics['error']}")
                
                # Show available metrics
                metric_keys = [k for k in metrics.keys() if k.startswith(('final_', 'best_'))]
                if metric_keys:
                    print(f"      ğŸ“ˆ Available metrics: {len(metric_keys)}")
                    for key in metric_keys[:3]:  # Show first 3 metrics
                        value = metrics[key]
                        if value is not None:
                            print(f"         {key}: {value:.4f}")
                
                if weights:
                    print(f"      ğŸ’¾ Model files:")
                    for weight_name, weight_info in weights.items():
                        size_mb = weight_info["size_mb"]
                        print(f"         {weight_name}: {size_mb:.1f}MB")
        else:
            print(f"\nâŒ KhÃ´ng tÃ¬m tháº¥y training runs nÃ o!")
        
        # Models hiá»‡n cÃ³
        existing = self.analysis_results.get("existing_models", {})
        if existing:
            print(f"\nğŸ¤– MODELS HIá»†N CÃ“:")
            for model_name, model_info in existing.items():
                model_type = model_info["model_type"]
                size_mb = model_info["size_mb"]
                print(f"   ğŸ“¦ {model_type}: {model_name} ({size_mb:.1f}MB)")
        
        # Training logs
        logs = self.analysis_results.get("training_logs", {})
        if logs:
            print(f"\nğŸ“ TRAINING LOGS:")
            for log_name, log_info in logs.items():
                size_kb = log_info["size_kb"]
                modified = log_info["modified"][:16]  # Just date and time
                print(f"   ğŸ“„ {log_name}: {size_kb:.1f}KB (modified: {modified})")
        
        # Model backups
        backups = self.analysis_results.get("model_backups", {})
        if backups:
            print(f"\nğŸ’¾ MODEL BACKUPS:")
            for backup_name, backup_info in backups.items():
                model_type = backup_info["model_type"]
                size_mb = backup_info["size_mb"]
                print(f"   ğŸ“¦ {model_type}: {backup_name} ({size_mb:.1f}MB)")
        
        # Training status assessment
        print(f"\nğŸ¯ ÄÃNH GIÃ TÃŒNH TRáº NG TRAINING:")
        
        if summary["completed_runs"] == 0:
            print("   ğŸ”´ ChÆ°a cÃ³ training runs nÃ o hoÃ n thÃ nh")
            print("   ğŸ’¡ Khuyáº¿n nghá»‹: Cháº¡y script train_all_models_1000_epochs.py")
        elif summary["completed_runs"] < 3:
            print(f"   ğŸŸ¡ CÃ³ {summary['completed_runs']}/3 models Ä‘Ã£ training xong")
            print("   ğŸ’¡ Khuyáº¿n nghá»‹: Tiáº¿p tá»¥c training cÃ¡c models cÃ²n láº¡i")
        else:
            print("   ğŸŸ¢ Táº¥t cáº£ 3 models Ä‘Ã£ training xong!")
            print("   ğŸ’¡ Sáºµn sÃ ng cho testing vÃ  deployment")
        
        print(f"\nâ±ï¸  THá»œI GIAN TRAINING Dá»° KIáº¾N:")
        print(f"   ğŸ”¥ 1000 epochs per model: ~8-12 giá»/model")
        print(f"   ğŸš€ Tá»•ng thá»i gian cho 3 models: ~24-36 giá»")
        
        print("\n" + "="*80)
        print("âœ¨ TRAINING ANALYSIS COMPLETED!")
        print("="*80)

def main():
    """Main function"""
    print("ğŸ¯ BÃO CÃO Tá»”NG Há»¢P TRAINING 1000 EPOCHS")
    print("="*50)
    
    analyzer = TrainingResultsAnalyzer()
    report_path = analyzer.generate_comprehensive_report()
    
    print(f"\nğŸ“„ Comprehensive report saved: {report_path}")
    print("\nğŸ”— Äá»ƒ tiáº¿p tá»¥c training:")
    print("   python train_all_models_1000_epochs.py")
    print("\nğŸ”— Äá»ƒ test models:")
    print("   python test_all_models.py")

if __name__ == "__main__":
    main()